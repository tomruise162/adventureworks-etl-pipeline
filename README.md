# Sales Category Analytics - Complete Data Engineering Project

Project hoÃ n chá»‰nh Ä‘á»ƒ load data tá»« SQL Server, xá»­ lÃ½ vá»›i Apache Spark, vÃ  táº¡o reports.

## TÃ­nh nÄƒng

- **Extract**: Load data tá»« SQL Server (AdventureWorks2022)
- **Transform**: Xá»­ lÃ½ vÃ  join data vá»›i Spark
- **Load**: LÆ°u data vÃ o data lake (Parquet format)
- **Reports**: Táº¡o reports CSV, JSON, vÃ  HTML Ä‘áº¹p máº¯t

## CÃ i Ä‘áº·t nhanh

### 1. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

### 2. Cáº¥u hÃ¬nh
Táº¡o file cáº¥u hÃ¬nh tá»« template:
```bash
# Copy template file
cp config/config.yaml.example config/config.yaml
```

Sau Ä‘Ã³ chá»‰nh sá»­a `config/config.yaml` vá»›i thÃ´ng tin database cá»§a báº¡n:
```yaml
database:
  username: "your_username"
  password: "your_password"
```

### 3. Cháº¡y pipeline
```bash
python scripts/main.py
```

## Cáº¥u trÃºc Project

```
SalesCategoryAnalytics/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml              # Cáº¥u hÃ¬nh database vÃ  Spark
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ basic/                   # Scripts há»c táº­p (xem scripts/basic/README.md)
â”‚   â”‚   â”œâ”€â”€ extract_data.py     # Script cÆ¡ báº£n Ä‘á»ƒ há»c extract data
â”‚   â”‚   â””â”€â”€ print_output.py     # Script cÆ¡ báº£n Ä‘á»ƒ test káº¿t ná»‘i
â”‚   â”œâ”€â”€ main.py                  # Script chÃ­nh - cháº¡y toÃ n bá»™ pipeline
â”‚   â”œâ”€â”€ etl_pipeline.py          # ETL pipeline (Extract, Transform, Load)
â”‚   â”œâ”€â”€ generate_reports.py     # Táº¡o reports tá»« analytics
â”‚   â””â”€â”€ utils.py                # Utility functions
â”œâ”€â”€ reports/                     # Reports Ä‘Æ°á»£c táº¡o á»Ÿ Ä‘Ã¢y
â”‚   â”œâ”€â”€ sales_by_year_*.csv
â”‚   â”œâ”€â”€ top_products_*.csv
â”‚   â”œâ”€â”€ sales_by_category_*.csv
â”‚   â””â”€â”€ sales_report_*.html     # HTML report Ä‘áº¹p
â”œâ”€â”€ logs/                        # Log files
â”‚   â””â”€â”€ etl_pipeline.log
â”œâ”€â”€ data_lake/                   # Data storage
â”‚   â””â”€â”€ adw/
â”‚       â”œâ”€â”€ raw/                # Raw data
â”‚       â””â”€â”€ analytics/         # Processed analytics
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ QUICK_START.md             # HÆ°á»›ng dáº«n nhanh
â””â”€â”€ README.md                   # File nÃ y
```

## CÃ¡ch sá»­ dá»¥ng

### Scripts Production (Khuyáº¿n nghá»‹)

**Cháº¡y pipeline hoÃ n chá»‰nh:**
```bash
python scripts/main.py
```

Script nÃ y sáº½:
1. Extract data tá»« SQL Server
2. Transform vÃ  join cÃ¡c báº£ng
3. Load vÃ o data lake
4. Táº¡o reports (CSV, JSON, HTML)

**Cháº¡y tá»«ng bÆ°á»›c riÃªng láº»:**

Chá»‰ cháº¡y ETL:
```bash
python scripts/etl_pipeline.py
```

Chá»‰ táº¡o reports (sau khi Ä‘Ã£ cháº¡y ETL):
```bash
python scripts/generate_reports.py
```

### Scripts Há»c Táº­p (Basic)

Náº¿u báº¡n muá»‘n há»c tá»«ng bÆ°á»›c cÆ¡ báº£n, cÃ³ thá»ƒ cháº¡y cÃ¡c scripts trong `scripts/basic/`:

```bash
# Test káº¿t ná»‘i vÃ  hiá»ƒn thá»‹ data Ä‘Æ¡n giáº£n
python scripts/basic/print_output.py

# Há»c cÃ¡ch extract data tá»« nhiá»u báº£ng
python scripts/basic/extract_data.py
```

**LÆ°u Ã½**: CÃ¡c scripts basic khÃ´ng cÃ³ error handling vÃ  config file, chá»‰ Ä‘á»ƒ há»c táº­p. Xem `scripts/basic/README.md` Ä‘á»ƒ biáº¿t thÃªm.

## Káº¿t quáº£

Sau khi cháº¡y xong, báº¡n sáº½ cÃ³:

### 1. Data trong Data Lake
- **Raw data**: `data_lake/adw/raw/` - Dá»¯ liá»‡u gá»‘c tá»« SQL Server
- **Analytics data**: `data_lake/adw/analytics/` - Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
  - `sales_by_year` - Doanh thu theo nÄƒm
  - `top_products` - Top 50 sáº£n pháº©m
  - `sales_by_category_year` - Doanh thu theo category vÃ  nÄƒm

### 2. Reports
Táº¥t cáº£ reports Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c `reports/`:

- **CSV Files**: 
  - `sales_by_year_YYYYMMDD_HHMMSS.csv`
  - `top_products_YYYYMMDD_HHMMSS.csv`
  - `sales_by_category_YYYYMMDD_HHMMSS.csv`

- **JSON Files**: TÆ°Æ¡ng tá»± nhÆ° CSV nhÆ°ng format JSON

- **HTML Report**: `sales_report_YYYYMMDD_HHMMSS.html`
  - Report Ä‘áº¹p máº¯t vá»›i charts vÃ  tables
  - Má»Ÿ báº±ng browser Ä‘á»ƒ xem

### 3. Logs
- `logs/etl_pipeline.log` - Chi tiáº¿t quÃ¡ trÃ¬nh cháº¡y

## Analytics Ä‘Æ°á»£c táº¡o

### 1. Sales by Year
Tá»•ng quan doanh thu theo nÄƒm:
- Total Revenue
- Average Order Value
- Order Count
- Unique Customers

### 2. Top Products
Top 50 sáº£n pháº©m bÃ¡n cháº¡y nháº¥t:
- Product Name
- Category
- Total Revenue
- Total Quantity
- Order Count
- Average Unit Price

### 3. Sales by Category and Year
Doanh thu chi tiáº¿t theo category vÃ  nÄƒm/thÃ¡ng:
- Category Name
- Year, Month
- Total Revenue
- Order Line Count
- Average Line Total
- Total Quantity

## Cáº¥u hÃ¬nh

File `config/config.yaml` chá»©a táº¥t cáº£ cáº¥u hÃ¬nh:

```yaml
database:
  server: "localhost"
  port: 1433
  database_name: "AdventureWorks2022"
  username: "sa"
  password: "123456"

hdfs:
  namenode: "file:///D:/DE_project/SalesCategoryAnalytics/data_lake"
  # Hoáº·c dÃ¹ng HDFS: "hdfs://localhost:9000"

spark:
  app_name: "SalesCategoryAnalytics"
  executor_memory: "2g"
  executor_cores: "2"
```

## YÃªu cáº§u há»‡ thá»‘ng

- Python 3.8+
- Apache Spark 3.x
- SQL Server vá»›i AdventureWorks2022 database
- JDBC Driver cho SQL Server (Ä‘Ã£ cÃ³ trong project)

## Troubleshooting

### Lá»—i káº¿t ná»‘i database
- Kiá»ƒm tra SQL Server Ä‘ang cháº¡y
- Kiá»ƒm tra username/password trong `config/config.yaml`
- Kiá»ƒm tra port 1433

### Lá»—i JDBC driver
- Kiá»ƒm tra Ä‘Æ°á»ng dáº«n driver trong `config/config.yaml`
- Äáº£m báº£o file `.jar` tá»“n táº¡i

### Lá»—i HDFS
- Náº¿u khÃ´ng cÃ³ HDFS, project sáº½ dÃ¹ng local filesystem
- Kiá»ƒm tra Ä‘Æ°á»ng dáº«n trong `config/config.yaml`

## Xem káº¿t quáº£

### Xem HTML Report
```bash
# Windows
start reports/sales_report_*.html

# Linux/Mac  
open reports/sales_report_*.html
```

### Xem CSV trong Excel
Má»Ÿ file CSV trong Excel hoáº·c báº¥t ká»³ spreadsheet nÃ o.

### Xem data trong Spark
```python
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("ViewData").getOrCreate()
df = spark.read.parquet("data_lake/adw/analytics/sales_by_year")
df.show()
```

## Há»— trá»£

Xem `QUICK_START.md` Ä‘á»ƒ hÆ°á»›ng dáº«n chi tiáº¿t hÆ¡n.

---

**Happy Analyzing! ğŸ“Š**
